# 部署指南

本文档详细说明如何将训练好的模型部署到RV1126嵌入式平台。

## 目录

1. [部署流程概述](#部署流程概述)
2. [模型转换](#模型转换)
3. [量化校准](#量化校准)
4. [嵌入式编译](#嵌入式编译)
5. [开发板部署](#开发板部署)
6. [性能调优](#性能调优)

---

## 部署流程概述

```
训练好的模型 (PyTorch .pt)
        ↓
    模型导出 (ONNX)
        ↓
    模型转换 (RKNN)
        ↓
    INT8量化
        ↓
    嵌入式程序编译
        ↓
    开发板部署运行
```

## 模型转换

### 步骤1: PyTorch → ONNX

```bash
python scripts/deploy/export_model.py \
    --weights outputs/weights/best.pt \
    --img-size 640 \
    --batch-size 1 \
    --simplify
```

**参数说明**：
- `--weights`: 训练好的PyTorch模型路径
- `--img-size`: 输入图像尺寸（需与训练时一致）
- `--batch-size`: 批量大小（嵌入式部署一般为1）
- `--simplify`: 简化ONNX图结构

**输出**：`outputs/weights/best.onnx`

### 步骤2: ONNX → RKNN

```bash
python scripts/deploy/convert_to_rknn.py \
    --onnx outputs/weights/best.onnx \
    --output outputs/weights/best.rknn \
    --platform rv1126 \
    --quantize int8 \
    --dataset data/processed/flir/calibration/
```

**参数说明**：
- `--onnx`: ONNX模型路径
- `--output`: RKNN模型输出路径
- `--platform`: 目标硬件平台
- `--quantize`: 量化类型（int8推荐）
- `--dataset`: 量化校准数据集

**输出**：`outputs/weights/best.rknn`

---

## 量化校准

### 校准数据集准备

1. **选择代表性图像**：从训练集中选取100-200张图像
2. **确保多样性**：包含不同场景、光照条件的样本
3. **图像预处理**：与推理时保持一致

```bash
# 准备校准数据集
mkdir -p data/processed/flir/calibration
# 复制代表性图像到校准目录
```

### 量化策略

| 量化类型 | 精度 | 速度 | 模型大小 |
|---------|------|------|---------|
| FP16 | 高 | 中 | 原始50% |
| INT8 | 中 | 快 | 原始25% |

**建议**：使用INT8量化，在精度损失可接受范围内获得最佳性能。

---

## 嵌入式编译

### 环境准备

```bash
# 安装交叉编译工具链
sudo apt-get install gcc-aarch64-linux-gnu g++-aarch64-linux-gnu

# 验证安装
aarch64-linux-gnu-gcc --version
```

### 编译步骤

```bash
cd embedded

# 创建构建目录
mkdir -p build && cd build

# 配置（交叉编译）
cmake .. -DCMAKE_TOOLCHAIN_FILE=../toolchain.cmake

# 编译
make -j$(nproc)
```

### 编译产物

```
embedded/build/
├── infrared_tracker      # 主程序
└── performance_test      # 性能测试工具
```

---

## 开发板部署

### 文件传输

```bash
# 创建目标目录
ssh root@rv1126 "mkdir -p /opt/infrared_tracker/{models,configs}"

# 传输可执行文件
scp build/infrared_tracker root@rv1126:/opt/infrared_tracker/

# 传输模型
scp ../../outputs/weights/best.rknn root@rv1126:/opt/infrared_tracker/models/

# 传输配置
scp ../configs/deploy.yaml root@rv1126:/opt/infrared_tracker/configs/
```

### 运行程序

```bash
# 登录开发板
ssh root@rv1126

# 运行程序
cd /opt/infrared_tracker
./infrared_tracker --model models/best.rknn --source /dev/video0
```

### 后台运行

```bash
# 使用nohup后台运行
nohup ./infrared_tracker --model models/best.rknn > tracker.log 2>&1 &

# 或使用systemd服务（参见embedded/部署说明.md）
```

---

## 性能调优

### 1. 模型层面

- **剪枝**：移除不重要的通道
- **量化**：使用INT8量化
- **蒸馏**：使用知识蒸馏压缩模型

### 2. 推理层面

- **批处理**：batch_size=1确保低延迟
- **异步推理**：流水线并行处理
- **内存池**：预分配避免动态分配

### 3. 系统层面

- **CPU亲和性**：绑定到特定核心
- **优先级调整**：使用实时调度
- **关闭不必要服务**：释放系统资源

### 性能目标

| 指标 | 目标值 | 说明 |
|-----|--------|------|
| 检测/跟踪FPS | ≥25 | 主要性能指标 |
| 端到端延迟 | ≤50ms | 实时性要求 |
| CPU使用率 | ≤60% | 留有余量 |
| 内存占用 | ≤200MB | 资源约束 |

---

## 常见问题

### 问：模型转换失败？
答：
1. 检查ONNX模型是否有不支持的算子
2. 尝试使用不同的opset版本
3. 查看RKNN Toolkit的兼容性列表

### 问：量化后精度下降严重？
答：
1. 增加校准数据集样本数
2. 使用混合精度量化
3. 对敏感层保持FP16

### 问：推理速度达不到要求？
答：
1. 确认NPU加速已启用
2. 检查是否有CPU fallback算子
3. 优化前后处理代码

### 问：内存溢出？
答：
1. 减小输入分辨率
2. 优化内存管理
3. 使用更小的模型
