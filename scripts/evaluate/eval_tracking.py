#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è·Ÿè¸ªç®—æ³•è¯„ä¼°è„šæœ¬ (æœ€ç»ˆå®Œæ•´ç‰ˆ)
åŠŸèƒ½åˆ—è¡¨ï¼š
1. å¤šç›®æ ‡è·Ÿè¸ªæ¨ç† (æ”¯æŒ DeepSORT/ByteTrack)
2. å®æ—¶å¯è§†åŒ– (ç»˜åˆ¶æ£€æµ‹æ¡†ã€IDã€ç±»åˆ«ã€è¿åŠ¨è½¨è¿¹)
3. ç»“æœä¿å­˜ (MP4 è§†é¢‘ + MOTæ ¼å¼ txt æ–‡ä»¶)
4. ç¨³å¥æ€§ä¿®å¤ (è§£å†³ Windows è·¯å¾„ä¹±ç ã€å‚æ•°ç¼ºå¤±ç­‰é—®é¢˜)
"""

import os
import sys
import argparse
import time
import traceback
from pathlib import Path
from datetime import datetime
import yaml
import cv2
import torch
import numpy as np
from tqdm import tqdm
from collections import deque

# ==============================================================================
# æ ¸å¿ƒè·¯å¾„ä¿®å¤ï¼šç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨ sys.path ä¸­ï¼Œé˜²æ­¢ ModuleNotFoundError
# ==============================================================================
FILE = Path(__file__).resolve()
ROOT = FILE.parents[2]  # æŒ‡å‘é¡¹ç›®æ ¹ç›®å½• (bishe/)
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))
# ==============================================================================

# ç”Ÿæˆå›ºå®šçš„é¢œè‰²è¡¨ï¼Œç”¨äºç»™ä¸åŒ ID åˆ†é…ä¸åŒé¢œè‰²
np.random.seed(42)
COLORS = np.random.randint(0, 255, size=(200, 3), dtype="uint8")


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='å¤šç›®æ ‡è·Ÿè¸ªè¯„ä¼°ä¸å¯è§†åŒ–')

    # æ ¸å¿ƒè¾“å…¥
    parser.add_argument('--weights', type=str, required=True, help='YOLOv5 æ£€æµ‹å™¨æƒé‡è·¯å¾„ (.pt)')
    parser.add_argument('--data', type=str, default='data/processed/flir/dataset.yaml',
                        help='æ•°æ®é›†é…ç½®æ–‡ä»¶ æˆ– è§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--tracker', type=str, default='deepsort', choices=['deepsort', 'bytetrack'],
                        help='é€‰æ‹©è·Ÿè¸ªç®—æ³•')

    # è¾“å‡ºè®¾ç½®
    parser.add_argument('--output', type=str, default='outputs/tracking', help='ç»“æœè¾“å‡ºç›®å½•')
    parser.add_argument('--save-vid', action='store_true', default=True, help='æ˜¯å¦ä¿å­˜ MP4 è§†é¢‘')
    parser.add_argument('--save-txt', action='store_true', default=True, help='æ˜¯å¦ä¿å­˜ MOT æ ¼å¼çš„ txt æŒ‡æ ‡æ–‡ä»¶')
    parser.add_argument('--show', action='store_true', help='æ˜¯å¦å®æ—¶å¼¹çª—æ˜¾ç¤º (æœåŠ¡å™¨ç«¯è¯·å…³é—­)')

    # ç®—æ³•å‚æ•°
    parser.add_argument('--conf-thres', type=float, default=0.25, help='æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ (ä½äºæ­¤å€¼çš„æ¡†ä¼šè¢«è¿‡æ»¤)')
    parser.add_argument('--nms-thres', type=float, default=0.45, help='NMS é˜ˆå€¼')
    parser.add_argument('--device', type=str, default='0', help='è®¡ç®—è®¾å¤‡ (ä¾‹å¦‚ 0 æˆ– cpu)')

    return parser.parse_args()


class TrackingRunner:
    """è·Ÿè¸ªæµç¨‹ç®¡ç†å™¨"""

    def __init__(self, args):
        self.args = args

        # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.save_dir = Path(args.output) / f'{args.tracker}_{self.timestamp}'
        self.save_dir.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ–è®¾å¤‡
        self.device = self._select_device(args.device)

        # åŠ è½½æ¨¡å‹
        self.detector = self._load_detector()
        self.tracker = self._create_tracker()

        # è½¨è¿¹å†å² (ç”¨äºç»˜åˆ¶æ‹–å°¾) {track_id: deque([(x,y), ...])}
        self.track_history = {}

    def _select_device(self, device):
        """å¤„ç†è®¾å¤‡å­—ç¬¦ä¸²"""
        if device.isdigit():
            return f'cuda:{device}'
        return device

    def _load_detector(self):
        """åŠ è½½ YOLOv5 æ£€æµ‹å™¨"""
        print(f'\n[1/3] åŠ è½½æ£€æµ‹å™¨: {self.args.weights}')
        try:
            from src.detection.yolov5_detector import create_yolov5_detector
            return create_yolov5_detector(
                model_path=str(self.args.weights),
                conf_threshold=self.args.conf_thres,
                nms_threshold=self.args.nms_thres,
                device=self.device,
                warmup=True
            )
        except Exception as e:
            print(f'âŒ æ£€æµ‹å™¨åŠ è½½å¤±è´¥: {e}')
            traceback.print_exc()
            sys.exit(1)

    def _create_tracker(self):
        """åˆå§‹åŒ–è·Ÿè¸ªå™¨ (DeepSORT æˆ– ByteTrack)"""
        print(f'\n[2/3] åˆå§‹åŒ–è·Ÿè¸ªå™¨: {self.args.tracker}')
        try:
            if self.args.tracker == 'deepsort':
                from src.tracking.deepsort_tracker import create_deepsort_tracker
                # æ³¨æ„ï¼šè¿™é‡Œç¡®ä¿ deepsort_tracker.py å·²ç»ä¿®å¤äº† n_init é—®é¢˜
                return create_deepsort_tracker(max_age=30, min_hits=3)

            elif self.args.tracker == 'bytetrack':
                from src.tracking.bytetrack_tracker import create_bytetrack_tracker
                return create_bytetrack_tracker(track_thresh=0.5, match_thresh=0.8)

        except Exception as e:
            print(f'âŒ è·Ÿè¸ªå™¨åˆå§‹åŒ–å¤±è´¥: {e}')
            print('æç¤º: è¯·æ£€æŸ¥ src/tracking/ ä¸‹çš„æ–‡ä»¶æ˜¯å¦å®Œæ•´ (åŒ…å« tracker.py, kalman_filter.py ç­‰)')
            traceback.print_exc()
            sys.exit(1)

    def _safe_read_image(self, path):
        """
        ã€å…³é”®ä¿®å¤ã€‘ç¨³å¥çš„å›¾ç‰‡è¯»å–æ–¹æ³•
        è§£å†³ Windows ä¸‹ cv2.imread è¯»å–ä¸­æ–‡æˆ–ç‰¹æ®Šå­—ç¬¦è·¯å¾„å¤±è´¥çš„é—®é¢˜
        """
        try:
            # å…ˆç”¨ numpy è¯»å–æ–‡ä»¶æµï¼Œå†ç”¨ cv2 è§£ç ï¼Œè¿™æ˜¯æœ€ç¨³å¦¥çš„æ–¹æ³•
            img_array = np.fromfile(path, dtype=np.uint8)
            img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
            return img
        except Exception:
            return None

    def _get_dataloader(self):
        """è§£æè¾“å…¥æºï¼Œè¿”å›æ•°æ®è¿­ä»£å™¨"""
        source = Path(self.args.data)
        is_video = source.is_file() and source.suffix.lower() in ['.mp4', '.avi', '.mkv', '.mov']

        # æƒ…å†µ A: è¾“å…¥æ˜¯ yaml é…ç½®æ–‡ä»¶
        if source.suffix.lower() in ['.yaml', '.yml']:
            print(f'   æ­£åœ¨è§£æé…ç½®æ–‡ä»¶: {source}')
            try:
                # å°è¯•å¤šç§ç¼–ç è¯»å–
                try:
                    with open(source, 'r', encoding='utf-8') as f:
                        config = yaml.safe_load(f)
                except UnicodeDecodeError:
                    with open(source, 'r', encoding='gbk') as f:
                        config = yaml.safe_load(f)
            except Exception as e:
                print(f'âŒ é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {e}')
                sys.exit(1)

            # ä¼˜å…ˆå¯»æ‰¾ test è·¯å¾„ï¼Œå…¶æ¬¡ val
            path_key = 'test' if 'test' in config else 'val'
            if path_key not in config:
                print('âŒ é”™è¯¯: é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ° test æˆ– val è·¯å¾„')
                sys.exit(1)

            base_path = Path(config.get('path', ''))
            rel_path = config[path_key]

            # å°è¯•æ‹¼æ¥ç»å¯¹è·¯å¾„
            candidates = [
                (base_path / rel_path) if not Path(rel_path).is_absolute() else Path(rel_path),
                Path(self.args.data).parent / rel_path,
                Path(rel_path)
            ]

            target_path = None
            for p in candidates:
                if p.exists():
                    target_path = p
                    break

            if not target_path:
                print(f'âŒ æ‰¾ä¸åˆ°å›¾ç‰‡ç›®å½•ï¼Œå°è¯•äº†ä»¥ä¸‹è·¯å¾„:\n' + '\n'.join([str(p) for p in candidates]))
                sys.exit(1)

            source = target_path
            is_video = False

        print(f'\n[3/3] æ•°æ®æºç¡®å®š: {source}')

        # è¿”å›è§†é¢‘æ•è·å¯¹è±¡ æˆ– å›¾ç‰‡åˆ—è¡¨
        if is_video:
            cap = cv2.VideoCapture(str(source))
            fps = int(cap.get(cv2.CAP_PROP_FPS))
            w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            return cap, fps, w, h, total_frames, True
        else:
            # å›¾ç‰‡æ–‡ä»¶å¤¹æ¨¡å¼
            valid_exts = ['.jpg', '.jpeg', '.png', '.bmp']
            files = sorted([p for p in source.rglob('*') if p.suffix.lower() in valid_exts])

            if not files:
                print(f'âŒ æ–‡ä»¶å¤¹ {source} ä¸ºç©ºæˆ–ä¸åŒ…å«å›¾ç‰‡')
                sys.exit(1)

            # è¯»å–ç¬¬ä¸€å¼ å›¾è·å–å°ºå¯¸
            img0 = self._safe_read_image(str(files[0]))
            if img0 is None:
                print('âŒ æ— æ³•è¯»å–ç¬¬ä¸€å¼ å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥è·¯å¾„æˆ–æƒé™')
                sys.exit(1)

            h, w = img0.shape[:2]
            return files, 30, w, h, len(files), False

    def draw_tracks(self, img, tracks):
        """
        æ ¸å¿ƒå¯è§†åŒ–å‡½æ•°
        ç»˜åˆ¶ï¼šæ£€æµ‹æ¡†ã€IDæ ‡ç­¾ã€ä¸­å¿ƒç‚¹è½¨è¿¹
        """
        for track in tracks:
            # å…¼å®¹ä¸åŒæ ¼å¼çš„ Track å¯¹è±¡
            if hasattr(track, 'bbox'):
                bbox = track.bbox
                tid = track.track_id
            elif hasattr(track, 'to_tlbr'):
                bbox = track.to_tlbr()
                tid = track.track_id
            else:
                continue  # æ— æ³•è§£æï¼Œè·³è¿‡

            # åæ ‡å–æ•´
            x1, y1, x2, y2 = [int(i) for i in bbox]
            cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)

            # æ ¹æ® ID è·å–é¢œè‰²
            color = [int(c) for c in COLORS[tid % len(COLORS)]]

            # 1. ç”»æ£€æµ‹æ¡†
            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)

            # 2. ç”» ID æ ‡ç­¾èƒŒæ™¯
            label = f'ID: {tid}'
            t_size = cv2.getTextSize(label, 0, fontScale=0.6, thickness=2)[0]
            cv2.rectangle(img, (x1, y1), (x1 + t_size[0] + 4, y1 - t_size[1] - 4), color, -1)

            # 3. ç”» ID æ–‡å­—
            cv2.putText(img, label, (x1 + 2, y1 - 2), 0, 0.6, [255, 255, 255], thickness=2, lineType=cv2.LINE_AA)

            # 4. ç”»è½¨è¿¹æ‹–å°¾ (Tail)
            if tid not in self.track_history:
                self.track_history[tid] = deque(maxlen=40)  # åªä¿ç•™æœ€è¿‘40å¸§çš„è½¨è¿¹
            self.track_history[tid].append((cx, cy))

            # å°†è½¨è¿¹ç‚¹è½¬ä¸º numpy æ•°ç»„å¹¶ç»˜åˆ¶æŠ˜çº¿
            points = np.hstack(self.track_history[tid]).astype(np.int32).reshape((-1, 1, 2))
            cv2.polylines(img, [points], isClosed=False, color=color, thickness=2)

        return img

    def run(self):
        """ä¸»æ‰§è¡Œå¾ªç¯"""
        # è·å–æ•°æ®åŠ è½½å™¨
        dataloader, fps, w, h, total_frames, is_video = self._get_dataloader()

        # åˆå§‹åŒ–ä¿å­˜å™¨
        vid_writer = None
        txt_file = None

        if self.args.save_vid:
            save_path = self.save_dir / 'result.mp4'
            vid_writer = cv2.VideoWriter(str(save_path), cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))
            print(f'   è§†é¢‘å°†ä¿å­˜è‡³: {save_path}')

        if self.args.save_txt:
            txt_path = self.save_dir / 'results.txt'
            txt_file = open(txt_path, 'w')
            print(f'   æŒ‡æ ‡å°†ä¿å­˜è‡³: {txt_path}')

        # ç»Ÿè®¡å˜é‡
        stats = {
            'total_tracks': set(),
            'frame_count': 0
        }

        print('\nğŸš€ å¼€å§‹è·Ÿè¸ªå¤„ç†...')
        pbar = tqdm(total=total_frames, desc='Tracking')

        while True:
            # ========================
            # 1. è¯»å–ä¸‹ä¸€å¸§
            # ========================
            if is_video:
                ret, frame = dataloader.read()
                if not ret: break
            else:
                if stats['frame_count'] >= len(dataloader): break
                # ä½¿ç”¨ç¨³å¥è¯»å–æ–¹æ³•
                frame = self._safe_read_image(str(dataloader[stats['frame_count']]))
                if frame is None:
                    # å¦‚æœæŸå¼ å›¾åäº†ï¼Œè·³è¿‡å®ƒï¼Œé˜²æ­¢ç¨‹åºå´©æºƒ
                    stats['frame_count'] += 1
                    pbar.update(1)
                    continue

            # ========================
            # 2. ç›®æ ‡æ£€æµ‹ (YOLOv5)
            # ========================
            det_result = self.detector.detect(frame)

            # æå–æ£€æµ‹ç»“æœ
            boxes, confs, clss = [], [], []
            if hasattr(det_result, 'boxes'):
                boxes = det_result.boxes  # xyxyæ ¼å¼
                confs = det_result.confidences
                clss = det_result.classes

            # ========================
            # 3. ç›®æ ‡è·Ÿè¸ª (DeepSORT/ByteTrack)
            # ========================
            tracks = []
            if len(boxes) > 0:
                try:
                    # æ ¼å¼è½¬æ¢: Tensor -> Numpy (å¦‚æœéœ€è¦)
                    if isinstance(boxes, torch.Tensor): boxes = boxes.cpu().numpy()
                    if isinstance(confs, torch.Tensor): confs = confs.cpu().numpy()
                    if isinstance(clss, torch.Tensor): clss = clss.cpu().numpy()

                    # è°ƒç”¨è·Ÿè¸ªå™¨
                    if self.args.tracker == 'deepsort':
                        # ã€é‡è¦ã€‘ä¼ å…¥ ori_img=frame ä»¥å¯ç”¨ ReID
                        result = self.tracker.update(detections=boxes, confidences=confs, ori_img=frame, classes=clss)
                    else:
                        # ByteTrack é€šå¸¸ä¸éœ€è¦åŸå›¾
                        result = self.tracker.update(boxes, confs, clss)

                    # ç»Ÿä¸€ç»“æœæ ¼å¼
                    if hasattr(result, 'tracks'):
                        tracks = result.tracks
                    else:
                        tracks = result

                except Exception as e:
                    # æ•è·è·Ÿè¸ªå™¨å†…éƒ¨é”™è¯¯ï¼Œæ‰“å°ä½†ä¸ä¸­æ–­ç¨‹åº
                    # print(f'\nâŒ è·Ÿè¸ªå‡ºé”™ (Frame {stats["frame_count"]}): {e}')
                    pass

            # ========================
            # 4. æ•°æ®è®°å½•ä¸å†™å…¥
            # ========================
            for track in tracks:
                # è§£æå±æ€§
                if hasattr(track, 'bbox'):
                    bbox = track.bbox
                elif hasattr(track, 'to_tlbr'):
                    bbox = track.to_tlbr()
                else:
                    continue

                tid = track.track_id
                conf = getattr(track, 'confidence', 1.0)

                # ç»Ÿè®¡å”¯ä¸€ ID
                stats['total_tracks'].add(tid)

                # å†™å…¥ MOT æ ¼å¼ (frame, id, left, top, w, h, conf, -1, -1, -1)
                # æ³¨æ„ï¼šMOT æ ¼å¼å¸§å·ä» 1 å¼€å§‹
                if txt_file:
                    x1, y1, x2, y2 = bbox
                    w_box = x2 - x1
                    h_box = y2 - y1
                    line = f"{stats['frame_count'] + 1},{tid},{x1:.2f},{y1:.2f},{w_box:.2f},{h_box:.2f},{conf:.2f},-1,-1,-1\n"
                    txt_file.write(line)

            # ========================
            # 5. å¯è§†åŒ–ä¸ä¿å­˜
            # ========================
            # åœ¨å›¾ä¸Šç”»æ¡†
            vis_frame = self.draw_tracks(frame.copy(), tracks)

            # åœ¨å·¦ä¸Šè§’æ˜¾ç¤ºå½“å‰å¸§ä¿¡æ¯
            info_text = f'Frame: {stats["frame_count"]} | Unique IDs: {len(stats["total_tracks"])}'
            cv2.putText(vis_frame, info_text, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)

            # å†™å…¥è§†é¢‘
            if vid_writer:
                vid_writer.write(vis_frame)

            # å®æ—¶æ˜¾ç¤º
            if self.args.show:
                cv2.imshow('Tracking Visualization', vis_frame)
                if cv2.waitKey(1) == ord('q'):
                    break

            # æ›´æ–°è¿›åº¦
            pbar.update(1)
            stats['frame_count'] += 1

        # ========================
        # 6. ç»“æŸæ¸…ç†
        # ========================
        pbar.close()
        if vid_writer: vid_writer.release()
        if is_video: dataloader.release()
        if txt_file: txt_file.close()
        cv2.destroyAllWindows()

        # æ‰“å°æœ€ç»ˆæŠ¥å‘Š
        print('\n' + '=' * 60)
        print('âœ… è·Ÿè¸ªè¯„ä¼°æµç¨‹ç»“æŸ')
        print(f'   ğŸ“‚ ç»“æœç›®å½•: {self.save_dir}')
        print(f'   ğŸ¥ ç»“æœè§†é¢‘: result.mp4')
        print(f'   ğŸ“„ æŒ‡æ ‡æ–‡ä»¶: results.txt')
        print('-' * 60)
        print(f"ğŸ“Š ç»Ÿè®¡æ‘˜è¦:")
        print(f"   - å¤„ç†æ€»å¸§æ•°: {stats['frame_count']}")
        print(f"   - æ•è·ç›®æ ‡æ€»æ•° (Total Unique IDs): {len(stats['total_tracks'])}")
        if stats['frame_count'] > 0:
            avg_obj = len(stats['total_tracks']) / (stats['frame_count'] / 30.0)  # ç²—ç•¥ä¼°ç®—
            # print(f"   - ä¼°ç®—æµé‡: {avg_obj:.2f} ä¸ª/ç§’")
        print('=' * 60)


def main():
    args = parse_args()
    runner = TrackingRunner(args)
    runner.run()


if __name__ == '__main__':
    main()